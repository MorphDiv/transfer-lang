{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "hired-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from pandas import DataFrame\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-headset",
   "metadata": {},
   "source": [
    "## Correlations using random samples of treebanks at different levels (language, genus, family)\n",
    "Weighted Tau correlations between LAS scores and:\n",
    "- Probes: Probe-A, Probe-L\n",
    "- BPE: BPE-based vectors, using squared Euclidean distance\n",
    "- msl, mwl: Mean Word Length, Mean Sentence, using squared Euclidean distance\n",
    "- Uriel (Lang2vec) \n",
    "\n",
    "**Random sampling:**\n",
    "1. For each language associated with more than one treebank, we randomly select just one treebank (the languages that initially had only one treebank remain the same)\n",
    "2. We adapt the dataframes of all the measures, so they contain only the selected treebanks of the random sample (we sample first for the columns:target languages and then for the rows: transfer lamguages)\n",
    "3. We calculate the correlations between the measures.\n",
    "4. We repeat the process using different random seeds (different random sampling of treebanks), and we average the correlations obtained in the different random samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-doctor",
   "metadata": {},
   "source": [
    "---\n",
    "Functions that we're going to need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "emerging-brunei",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "\n",
    "def correlation_flatten(df1, df2):\n",
    "    taus={}\n",
    "    \n",
    "    tau, p_value = stats.spearmanr(df1.transpose().to_numpy().flatten(), df2.transpose().to_numpy().flatten(), nan_policy='omit') #Spearman Correlation\n",
    "    return(tau)  #returns the correlation between two distance matrices \n",
    "##########################################3\n",
    "\n",
    "def assign_nans(df1):# Input: a dataframe\n",
    "                     #Output: a dataframe with NaNs values instead of the score when the trasnfer and target are the same UD\n",
    "#if col=row put a Nan\n",
    "    for col in df1.columns:\n",
    "        for row in df1[col].index:\n",
    "            if col==row:\n",
    "                #print(col, row, df1.loc[row, col])\n",
    "                df1.loc[row, col]=np.NaN\n",
    "    return(df1)\n",
    "            \n",
    "\n",
    "#idea firs sample columns, then rows\n",
    "##################################################################################\n",
    "def sample_treebanks(original, seed, mode): #Input: A dataframe with  UD treebanks (columns: target treebank rows: transfer treebank), \n",
    "                                                #A random seed\n",
    "                                            #Ouput: A list with a sample of treebanks (one per language)\n",
    "    UDs= defaultdict(list)\n",
    "    if mode ==\"columns\":\n",
    "        treebanks=original.columns\n",
    "    else:\n",
    "        treebanks=original.index\n",
    "    \n",
    "    for col in treebanks:  #All languages treebanks (columns)\n",
    "        tmplist=[]\n",
    "        x = col.split(\"UD_\")[1].split(\"-\")\n",
    "        languagename=x[0] #Language Name\n",
    "        #print (languagename, col)\n",
    "        tmplist.append(col)\n",
    "        #Create a Dictionary languagename:(treebank1, treebank2, ...)\n",
    "        if languagename not in UDs:\n",
    "            UDs[languagename]=tmplist\n",
    "        else:\n",
    "            UDs[languagename].append(col)\n",
    "    #UDs contains each languagename and the associated treebanks\n",
    "    \n",
    "    ####Random sampling:#####\n",
    "    random.seed(a=seed)\n",
    "\n",
    "    #Foreach key (language name) randomly select just one treebank:  if array greater than 1, sample, assign to new dict\n",
    "    UDs_sampled= defaultdict(list)  #UDs_sampled contains each languagename and the randomly selected treebank\n",
    "    for key, value in UDs.items() :\n",
    "        if len(value)>1: #only for Languages with more than one UD\n",
    "            #print (key, value)\n",
    "            randomtreebank=random.choice(value)\n",
    "            UDs_sampled[key]=randomtreebank\n",
    "        else:\n",
    "            UDs_sampled[key]=value[0] #Languages with only one treebank, remain the same. \n",
    "\n",
    "    #print(UDs_sampled)\n",
    "\n",
    "    sample=list(UDs_sampled.values())  #The random sample\n",
    "    return sample\n",
    "\n",
    "###################\n",
    "\n",
    "def sample_phylogenetic(field, df_genus, k, s): \n",
    "    names=df_genus[field].value_counts().index  #name of  genus in the dataset\n",
    "    strings=[]\n",
    "    for n in names:\n",
    "\n",
    "        filtered=genus[genus[field]==n]\n",
    "        filtered=filtered.sample(n=k, random_state=s)  #numer of random samples\n",
    "        language=filtered[\"long_name\"].tolist()[0]\n",
    "        language=language.replace(\" \", \"_\")\n",
    "        language=\"UD_\"+language+\"-\"\n",
    "        strings.append(language)\n",
    "        \n",
    "    return (strings)  #Return a List of sampled  pefixes, e.g., 'UD_Old_Church_Slavonic-', 'UD_German-', 'UD_Romanian-',..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-skiing",
   "metadata": {},
   "source": [
    "Reading the distance matrices for each measure (columns: target languages; rows: transfer languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "atomic-bradley",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAS (78, 116)\n",
      "BPE (78, 116)\n",
      "Probe-L (78, 116)\n",
      "Probe-A (78, 116)\n",
      "MWL (78, 116)\n",
      "MSL (78, 116)\n",
      "L2V (78, 116)\n"
     ]
    }
   ],
   "source": [
    "las_path=\"../data/las_distances.tsv\"\n",
    "bpe_path=\"../data/bpe_distances.tsv\"\n",
    "deprel_path=\"../data/deprel_distances.tsv\"\n",
    "struct_path=\"../data/struct_distances.tsv\"\n",
    "mwl_path=\"../data/mwl_distances.tsv\"\n",
    "msl_path=\"../data/msl_distances.tsv\"\n",
    "l2v_path=\"../data/l2v_distances.tsv\" \n",
    "\n",
    "bpe = pd.read_csv(bpe_path,index_col=0, sep=\"\\t\")\n",
    "las = pd.read_csv(las_path,index_col=0, sep=\"\\t\")\n",
    "mwl = pd.read_csv(mwl_path,index_col=0, sep=\"\\t\")\n",
    "msl = pd.read_csv(msl_path,index_col=0, sep=\"\\t\")\n",
    "l2v = pd.read_csv(l2v_path,index_col=0, sep=\"\\t\")\n",
    "deprel = pd.read_csv(deprel_path,index_col=0, sep=\"\\t\")\n",
    "struct = pd.read_csv(struct_path,index_col=0, sep=\"\\t\")\n",
    "\n",
    "las=assign_nans(las)\n",
    "bpe=assign_nans(bpe)\n",
    "mwl=assign_nans(mwl)\n",
    "msl=assign_nans(msl)\n",
    "l2v=assign_nans(l2v)\n",
    "deprel=assign_nans(deprel)\n",
    "struct=assign_nans(struct)\n",
    "\n",
    "\n",
    "print(\"LAS\", las.shape)\n",
    "print(\"BPE\", bpe.shape)\n",
    "print(\"Probe-L\", deprel.shape)\n",
    "print(\"Probe-A\", struct.shape)\n",
    "print(\"MWL\", mwl.shape)\n",
    "print(\"MSL\", msl.shape)\n",
    "print(\"L2V\", l2v.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "tired-sullivan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UD_Afrikaans-AfriBooms</th>\n",
       "      <th>UD_Ancient_Greek-PROIEL</th>\n",
       "      <th>UD_Ancient_Greek-Perseus</th>\n",
       "      <th>UD_Arabic-PADT</th>\n",
       "      <th>UD_Armenian-ArmTDP</th>\n",
       "      <th>UD_Basque-BDT</th>\n",
       "      <th>UD_Belarusian-HSE</th>\n",
       "      <th>UD_Bulgarian-BTB</th>\n",
       "      <th>UD_Catalan-AnCora</th>\n",
       "      <th>UD_Chinese-GSD</th>\n",
       "      <th>...</th>\n",
       "      <th>UD_Turkish-Penn</th>\n",
       "      <th>UD_Turkish-Tourism</th>\n",
       "      <th>UD_Turkish_German-SAGT</th>\n",
       "      <th>UD_Ukrainian-IU</th>\n",
       "      <th>UD_Urdu-UDTB</th>\n",
       "      <th>UD_Uyghur-UDT</th>\n",
       "      <th>UD_Vietnamese-VTB</th>\n",
       "      <th>UD_Welsh-CCG</th>\n",
       "      <th>UD_Western_Armenian-ArmTDP</th>\n",
       "      <th>UD_Wolof-WTB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UD_Ancient_Greek-PROIEL</th>\n",
       "      <td>0.239045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.394669</td>\n",
       "      <td>0.096090</td>\n",
       "      <td>0.192595</td>\n",
       "      <td>0.137580</td>\n",
       "      <td>0.276568</td>\n",
       "      <td>0.247747</td>\n",
       "      <td>0.192340</td>\n",
       "      <td>0.075811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195167</td>\n",
       "      <td>0.101013</td>\n",
       "      <td>0.188286</td>\n",
       "      <td>0.266921</td>\n",
       "      <td>0.085591</td>\n",
       "      <td>0.035231</td>\n",
       "      <td>0.120809</td>\n",
       "      <td>0.163681</td>\n",
       "      <td>0.204588</td>\n",
       "      <td>0.029701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UD_Ancient_Greek-Perseus</th>\n",
       "      <td>0.167200</td>\n",
       "      <td>0.444038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.092242</td>\n",
       "      <td>0.214099</td>\n",
       "      <td>0.191201</td>\n",
       "      <td>0.267717</td>\n",
       "      <td>0.244826</td>\n",
       "      <td>0.139874</td>\n",
       "      <td>0.118850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240921</td>\n",
       "      <td>0.222576</td>\n",
       "      <td>0.192453</td>\n",
       "      <td>0.266205</td>\n",
       "      <td>0.082642</td>\n",
       "      <td>0.083145</td>\n",
       "      <td>0.172573</td>\n",
       "      <td>0.137470</td>\n",
       "      <td>0.232473</td>\n",
       "      <td>0.051575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UD_Arabic-PADT</th>\n",
       "      <td>0.218732</td>\n",
       "      <td>0.108263</td>\n",
       "      <td>0.101107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.208489</td>\n",
       "      <td>0.169081</td>\n",
       "      <td>0.402737</td>\n",
       "      <td>0.391634</td>\n",
       "      <td>0.276109</td>\n",
       "      <td>0.083472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177295</td>\n",
       "      <td>0.060396</td>\n",
       "      <td>0.155413</td>\n",
       "      <td>0.410721</td>\n",
       "      <td>0.075372</td>\n",
       "      <td>0.073281</td>\n",
       "      <td>0.229894</td>\n",
       "      <td>0.315085</td>\n",
       "      <td>0.205379</td>\n",
       "      <td>0.074152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UD_Basque-BDT</th>\n",
       "      <td>0.317848</td>\n",
       "      <td>0.117199</td>\n",
       "      <td>0.130834</td>\n",
       "      <td>0.166166</td>\n",
       "      <td>0.472700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.411713</td>\n",
       "      <td>0.398098</td>\n",
       "      <td>0.319768</td>\n",
       "      <td>0.279713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467115</td>\n",
       "      <td>0.349831</td>\n",
       "      <td>0.326183</td>\n",
       "      <td>0.410165</td>\n",
       "      <td>0.230711</td>\n",
       "      <td>0.088031</td>\n",
       "      <td>0.326646</td>\n",
       "      <td>0.254811</td>\n",
       "      <td>0.449224</td>\n",
       "      <td>0.081778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UD_Belarusian-HSE</th>\n",
       "      <td>0.442731</td>\n",
       "      <td>0.215646</td>\n",
       "      <td>0.204518</td>\n",
       "      <td>0.259601</td>\n",
       "      <td>0.502431</td>\n",
       "      <td>0.344594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714153</td>\n",
       "      <td>0.531711</td>\n",
       "      <td>0.249625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412210</td>\n",
       "      <td>0.199614</td>\n",
       "      <td>0.375029</td>\n",
       "      <td>0.795355</td>\n",
       "      <td>0.203415</td>\n",
       "      <td>0.046787</td>\n",
       "      <td>0.344016</td>\n",
       "      <td>0.414289</td>\n",
       "      <td>0.465441</td>\n",
       "      <td>0.111780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UD_Turkish-Penn</th>\n",
       "      <td>0.257476</td>\n",
       "      <td>0.064240</td>\n",
       "      <td>0.078834</td>\n",
       "      <td>0.078004</td>\n",
       "      <td>0.305348</td>\n",
       "      <td>0.231998</td>\n",
       "      <td>0.324776</td>\n",
       "      <td>0.315930</td>\n",
       "      <td>0.204929</td>\n",
       "      <td>0.223565</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.482972</td>\n",
       "      <td>0.300486</td>\n",
       "      <td>0.321164</td>\n",
       "      <td>0.223373</td>\n",
       "      <td>0.134254</td>\n",
       "      <td>0.137137</td>\n",
       "      <td>0.136474</td>\n",
       "      <td>0.296351</td>\n",
       "      <td>0.043849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UD_Turkish-Tourism</th>\n",
       "      <td>0.040624</td>\n",
       "      <td>0.029593</td>\n",
       "      <td>0.045358</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.071055</td>\n",
       "      <td>0.058145</td>\n",
       "      <td>0.063649</td>\n",
       "      <td>0.045932</td>\n",
       "      <td>0.021022</td>\n",
       "      <td>0.041696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.055097</td>\n",
       "      <td>0.046369</td>\n",
       "      <td>0.056580</td>\n",
       "      <td>0.188181</td>\n",
       "      <td>0.028140</td>\n",
       "      <td>0.024884</td>\n",
       "      <td>0.074261</td>\n",
       "      <td>0.022577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UD_Ukrainian-IU</th>\n",
       "      <td>0.473951</td>\n",
       "      <td>0.206636</td>\n",
       "      <td>0.190919</td>\n",
       "      <td>0.262757</td>\n",
       "      <td>0.516455</td>\n",
       "      <td>0.364266</td>\n",
       "      <td>0.753688</td>\n",
       "      <td>0.725030</td>\n",
       "      <td>0.602642</td>\n",
       "      <td>0.280186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458965</td>\n",
       "      <td>0.334298</td>\n",
       "      <td>0.385678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.223647</td>\n",
       "      <td>0.062758</td>\n",
       "      <td>0.363210</td>\n",
       "      <td>0.460186</td>\n",
       "      <td>0.489865</td>\n",
       "      <td>0.097933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UD_Urdu-UDTB</th>\n",
       "      <td>0.404363</td>\n",
       "      <td>0.106578</td>\n",
       "      <td>0.114931</td>\n",
       "      <td>0.110944</td>\n",
       "      <td>0.447270</td>\n",
       "      <td>0.419797</td>\n",
       "      <td>0.387358</td>\n",
       "      <td>0.393312</td>\n",
       "      <td>0.249689</td>\n",
       "      <td>0.234463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.495139</td>\n",
       "      <td>0.373951</td>\n",
       "      <td>0.286751</td>\n",
       "      <td>0.420743</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.177377</td>\n",
       "      <td>0.191767</td>\n",
       "      <td>0.197412</td>\n",
       "      <td>0.410758</td>\n",
       "      <td>0.035922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UD_Western_Armenian-ArmTDP</th>\n",
       "      <td>0.424111</td>\n",
       "      <td>0.210152</td>\n",
       "      <td>0.208358</td>\n",
       "      <td>0.188255</td>\n",
       "      <td>0.745512</td>\n",
       "      <td>0.460926</td>\n",
       "      <td>0.606239</td>\n",
       "      <td>0.573560</td>\n",
       "      <td>0.452914</td>\n",
       "      <td>0.293611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545896</td>\n",
       "      <td>0.350796</td>\n",
       "      <td>0.362219</td>\n",
       "      <td>0.633898</td>\n",
       "      <td>0.296002</td>\n",
       "      <td>0.056276</td>\n",
       "      <td>0.298767</td>\n",
       "      <td>0.328578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.113185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            UD_Afrikaans-AfriBooms  UD_Ancient_Greek-PROIEL  \\\n",
       "UD_Ancient_Greek-PROIEL                   0.239045                      NaN   \n",
       "UD_Ancient_Greek-Perseus                  0.167200                 0.444038   \n",
       "UD_Arabic-PADT                            0.218732                 0.108263   \n",
       "UD_Basque-BDT                             0.317848                 0.117199   \n",
       "UD_Belarusian-HSE                         0.442731                 0.215646   \n",
       "...                                            ...                      ...   \n",
       "UD_Turkish-Penn                           0.257476                 0.064240   \n",
       "UD_Turkish-Tourism                        0.040624                 0.029593   \n",
       "UD_Ukrainian-IU                           0.473951                 0.206636   \n",
       "UD_Urdu-UDTB                              0.404363                 0.106578   \n",
       "UD_Western_Armenian-ArmTDP                0.424111                 0.210152   \n",
       "\n",
       "                            UD_Ancient_Greek-Perseus  UD_Arabic-PADT  \\\n",
       "UD_Ancient_Greek-PROIEL                     0.394669        0.096090   \n",
       "UD_Ancient_Greek-Perseus                         NaN        0.092242   \n",
       "UD_Arabic-PADT                              0.101107             NaN   \n",
       "UD_Basque-BDT                               0.130834        0.166166   \n",
       "UD_Belarusian-HSE                           0.204518        0.259601   \n",
       "...                                              ...             ...   \n",
       "UD_Turkish-Penn                             0.078834        0.078004   \n",
       "UD_Turkish-Tourism                          0.045358        0.007581   \n",
       "UD_Ukrainian-IU                             0.190919        0.262757   \n",
       "UD_Urdu-UDTB                                0.114931        0.110944   \n",
       "UD_Western_Armenian-ArmTDP                  0.208358        0.188255   \n",
       "\n",
       "                            UD_Armenian-ArmTDP  UD_Basque-BDT  \\\n",
       "UD_Ancient_Greek-PROIEL               0.192595       0.137580   \n",
       "UD_Ancient_Greek-Perseus              0.214099       0.191201   \n",
       "UD_Arabic-PADT                        0.208489       0.169081   \n",
       "UD_Basque-BDT                         0.472700            NaN   \n",
       "UD_Belarusian-HSE                     0.502431       0.344594   \n",
       "...                                        ...            ...   \n",
       "UD_Turkish-Penn                       0.305348       0.231998   \n",
       "UD_Turkish-Tourism                    0.071055       0.058145   \n",
       "UD_Ukrainian-IU                       0.516455       0.364266   \n",
       "UD_Urdu-UDTB                          0.447270       0.419797   \n",
       "UD_Western_Armenian-ArmTDP            0.745512       0.460926   \n",
       "\n",
       "                            UD_Belarusian-HSE  UD_Bulgarian-BTB  \\\n",
       "UD_Ancient_Greek-PROIEL              0.276568          0.247747   \n",
       "UD_Ancient_Greek-Perseus             0.267717          0.244826   \n",
       "UD_Arabic-PADT                       0.402737          0.391634   \n",
       "UD_Basque-BDT                        0.411713          0.398098   \n",
       "UD_Belarusian-HSE                         NaN          0.714153   \n",
       "...                                       ...               ...   \n",
       "UD_Turkish-Penn                      0.324776          0.315930   \n",
       "UD_Turkish-Tourism                   0.063649          0.045932   \n",
       "UD_Ukrainian-IU                      0.753688          0.725030   \n",
       "UD_Urdu-UDTB                         0.387358          0.393312   \n",
       "UD_Western_Armenian-ArmTDP           0.606239          0.573560   \n",
       "\n",
       "                            UD_Catalan-AnCora  UD_Chinese-GSD  ...  \\\n",
       "UD_Ancient_Greek-PROIEL              0.192340        0.075811  ...   \n",
       "UD_Ancient_Greek-Perseus             0.139874        0.118850  ...   \n",
       "UD_Arabic-PADT                       0.276109        0.083472  ...   \n",
       "UD_Basque-BDT                        0.319768        0.279713  ...   \n",
       "UD_Belarusian-HSE                    0.531711        0.249625  ...   \n",
       "...                                       ...             ...  ...   \n",
       "UD_Turkish-Penn                      0.204929        0.223565  ...   \n",
       "UD_Turkish-Tourism                   0.021022        0.041696  ...   \n",
       "UD_Ukrainian-IU                      0.602642        0.280186  ...   \n",
       "UD_Urdu-UDTB                         0.249689        0.234463  ...   \n",
       "UD_Western_Armenian-ArmTDP           0.452914        0.293611  ...   \n",
       "\n",
       "                            UD_Turkish-Penn  UD_Turkish-Tourism  \\\n",
       "UD_Ancient_Greek-PROIEL            0.195167            0.101013   \n",
       "UD_Ancient_Greek-Perseus           0.240921            0.222576   \n",
       "UD_Arabic-PADT                     0.177295            0.060396   \n",
       "UD_Basque-BDT                      0.467115            0.349831   \n",
       "UD_Belarusian-HSE                  0.412210            0.199614   \n",
       "...                                     ...                 ...   \n",
       "UD_Turkish-Penn                         NaN            0.482972   \n",
       "UD_Turkish-Tourism                 0.166714                 NaN   \n",
       "UD_Ukrainian-IU                    0.458965            0.334298   \n",
       "UD_Urdu-UDTB                       0.495139            0.373951   \n",
       "UD_Western_Armenian-ArmTDP         0.545896            0.350796   \n",
       "\n",
       "                            UD_Turkish_German-SAGT  UD_Ukrainian-IU  \\\n",
       "UD_Ancient_Greek-PROIEL                   0.188286         0.266921   \n",
       "UD_Ancient_Greek-Perseus                  0.192453         0.266205   \n",
       "UD_Arabic-PADT                            0.155413         0.410721   \n",
       "UD_Basque-BDT                             0.326183         0.410165   \n",
       "UD_Belarusian-HSE                         0.375029         0.795355   \n",
       "...                                            ...              ...   \n",
       "UD_Turkish-Penn                           0.300486         0.321164   \n",
       "UD_Turkish-Tourism                        0.055097         0.046369   \n",
       "UD_Ukrainian-IU                           0.385678              NaN   \n",
       "UD_Urdu-UDTB                              0.286751         0.420743   \n",
       "UD_Western_Armenian-ArmTDP                0.362219         0.633898   \n",
       "\n",
       "                            UD_Urdu-UDTB  UD_Uyghur-UDT  UD_Vietnamese-VTB  \\\n",
       "UD_Ancient_Greek-PROIEL         0.085591       0.035231           0.120809   \n",
       "UD_Ancient_Greek-Perseus        0.082642       0.083145           0.172573   \n",
       "UD_Arabic-PADT                  0.075372       0.073281           0.229894   \n",
       "UD_Basque-BDT                   0.230711       0.088031           0.326646   \n",
       "UD_Belarusian-HSE               0.203415       0.046787           0.344016   \n",
       "...                                  ...            ...                ...   \n",
       "UD_Turkish-Penn                 0.223373       0.134254           0.137137   \n",
       "UD_Turkish-Tourism              0.056580       0.188181           0.028140   \n",
       "UD_Ukrainian-IU                 0.223647       0.062758           0.363210   \n",
       "UD_Urdu-UDTB                         NaN       0.177377           0.191767   \n",
       "UD_Western_Armenian-ArmTDP      0.296002       0.056276           0.298767   \n",
       "\n",
       "                            UD_Welsh-CCG  UD_Western_Armenian-ArmTDP  \\\n",
       "UD_Ancient_Greek-PROIEL         0.163681                    0.204588   \n",
       "UD_Ancient_Greek-Perseus        0.137470                    0.232473   \n",
       "UD_Arabic-PADT                  0.315085                    0.205379   \n",
       "UD_Basque-BDT                   0.254811                    0.449224   \n",
       "UD_Belarusian-HSE               0.414289                    0.465441   \n",
       "...                                  ...                         ...   \n",
       "UD_Turkish-Penn                 0.136474                    0.296351   \n",
       "UD_Turkish-Tourism              0.024884                    0.074261   \n",
       "UD_Ukrainian-IU                 0.460186                    0.489865   \n",
       "UD_Urdu-UDTB                    0.197412                    0.410758   \n",
       "UD_Western_Armenian-ArmTDP      0.328578                         NaN   \n",
       "\n",
       "                            UD_Wolof-WTB  \n",
       "UD_Ancient_Greek-PROIEL         0.029701  \n",
       "UD_Ancient_Greek-Perseus        0.051575  \n",
       "UD_Arabic-PADT                  0.074152  \n",
       "UD_Basque-BDT                   0.081778  \n",
       "UD_Belarusian-HSE               0.111780  \n",
       "...                                  ...  \n",
       "UD_Turkish-Penn                 0.043849  \n",
       "UD_Turkish-Tourism              0.022577  \n",
       "UD_Ukrainian-IU                 0.097933  \n",
       "UD_Urdu-UDTB                    0.035922  \n",
       "UD_Western_Armenian-ArmTDP      0.113185  \n",
       "\n",
       "[78 rows x 116 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "las"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-joseph",
   "metadata": {},
   "source": [
    " - **Language level**\n",
    " \n",
    "Calculating correlations for the treebanks random samples (one treebank per language):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "important-consolidation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######\n",
      "Mean and standard deviation over the different samples:\n",
      "r(Probe-L,las) -0.5731838078042815 SD: 0.026800966222526614\n",
      "r(Probe-A,las) -0.6614008678924165 SD: 0.015241501589277208\n",
      "r(bpe,las) -0.39355601697022224 SD: 0.014751773954518614\n",
      "r(msl,las) -0.12461642784867656 SD: 0.02680313409677038\n",
      "r(mwl,las) -0.3836948878682873 SD: 0.018316005021113052\n",
      "r(l2v,las) -0.4800453500752769 SD: 0.009048928510701418\n"
     ]
    }
   ],
   "source": [
    "deprel_means= [] \n",
    "struct_means= []\n",
    "bpe_means= []\n",
    "msl_means= []\n",
    "mwl_means= []\n",
    "l2v_means= []\n",
    "l2vvslas_detailed=[]\n",
    "mwlvslas_detailed=[]\n",
    "mslvslas_detailed=[]\n",
    "bpevslas_detailed=[]\n",
    "deprelvslas_detailed=[]\n",
    "structvslas_detailed=[]\n",
    "for s in range(1, 31): #random seeds\n",
    "    randomsample_columns=sample_treebanks(las, s, \"columns\")  #returns a list with the a random sample of treebanks. The new sample will have only one treebank per language\n",
    "    randomsample_rows=sample_treebanks(las, s, \"rows\")  #returns a list with the a random sample of treebanks. The new sample will have only one treebank per language\n",
    "\n",
    "    \n",
    "    #We addapt the dataframes (rows and columns) so they contain only the treebanks in the random sample \n",
    "\n",
    "    bpe_sampled=bpe[[c for c in bpe.columns if c in randomsample_columns]]\n",
    "    bpe_sampled=bpe_sampled.loc[bpe_sampled.index.intersection(randomsample_rows)] \n",
    "\n",
    "    l2v_sampled=l2v[[c for c in l2v.columns if c in randomsample_columns]]\n",
    "    l2v_sampled=l2v_sampled.loc[l2v_sampled.index.intersection(randomsample_rows)]  \n",
    "\n",
    "    las_sampled=las[[c for c in las.columns if c in randomsample_columns]]\n",
    "    las_sampled=las_sampled.loc[las_sampled.index.intersection(randomsample_rows)]  \n",
    "\n",
    "    msl_sampled=msl[[c for c in msl.columns if c in randomsample_columns]]\n",
    "    msl_sampled=msl_sampled.loc[msl_sampled.index.intersection(randomsample_rows)]  \n",
    "\n",
    "    mwl_sampled=mwl[[c for c in mwl.columns if c in randomsample_columns]]\n",
    "    mwl_sampled=mwl_sampled.loc[mwl_sampled.index.intersection(randomsample_rows)]  \n",
    "\n",
    "    struct_sampled=struct[[c for c in struct.columns if c in randomsample_columns]]\n",
    "    struct_sampled=struct_sampled.loc[struct_sampled.index.intersection(randomsample_rows)]  \n",
    "\n",
    "    deprel_sampled=deprel[[c for c in deprel.columns if c in randomsample_columns]]\n",
    "    deprel_sampled=deprel_sampled.loc[deprel_sampled.index.intersection(randomsample_rows)]  \n",
    "    \n",
    "        \n",
    "\n",
    "    #We store the results  for each random sample (seed)\n",
    "    deprel_means.append( correlation_flatten(deprel_sampled, las_sampled)) \n",
    "    struct_means.append(correlation_flatten(struct_sampled, las_sampled))\n",
    "    bpe_means.append(correlation_flatten(bpe_sampled, las_sampled))\n",
    "    msl_means.append(correlation_flatten(msl_sampled, las_sampled))\n",
    "    mwl_means.append(correlation_flatten(mwl_sampled, las_sampled))\n",
    "    l2v_means.append(correlation_flatten(l2v_sampled, las_sampled))\n",
    "#We print the mean taking into account all the random samples of treebanks:\n",
    "print(\"######\")\n",
    "print (\"Mean and standard deviation over the different samples:\")\n",
    "print (\"r(Probe-L,las)\", statistics.mean(deprel_means), \"SD:\", statistics.stdev(deprel_means))\n",
    "print(\"r(Probe-A,las)\",statistics.mean(struct_means), \"SD:\", statistics.stdev(struct_means) )\n",
    "print(\"r(bpe,las)\", statistics.mean(bpe_means), \"SD:\", statistics.stdev(bpe_means) )\n",
    "print(\"r(msl,las)\", statistics.mean(msl_means), \"SD:\", statistics.stdev(msl_means) )\n",
    "print(\"r(mwl,las)\", statistics.mean(mwl_means), \"SD:\", statistics.stdev(mwl_means) )\n",
    "print(\"r(l2v,las)\", statistics.mean(l2v_means), \"SD:\", statistics.stdev(l2v_means) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-idaho",
   "metadata": {},
   "source": [
    " - **Genus level**\n",
    " \n",
    "Calculating correlations for the treebanks random samples (one treebank per genus):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "featured-separate",
   "metadata": {},
   "outputs": [],
   "source": [
    "genus_path=\"../data/genus_family.tsv\"\n",
    "genus = pd.read_csv(genus_path,index_col=0, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-subscriber",
   "metadata": {},
   "source": [
    "Language families:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "amateur-spyware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indo-European     47\n",
       "Afro-Asiatic       4\n",
       "Uralic             3\n",
       "Sino-Tibetan       2\n",
       "Turkic             2\n",
       "Dravidian          2\n",
       "Atlantic-Congo     1\n",
       "Basque             1\n",
       "Austroasiatic      1\n",
       "Austronesian       1\n",
       "Koreanic           1\n",
       "Japonic            1\n",
       "Sign Language      1\n",
       "Name: family, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genus['family'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "rural-trinidad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Balto-Slavic              14\n",
       "Germanic                  13\n",
       "Italic                     9\n",
       "Indo-Iranian               4\n",
       "Celtic                     3\n",
       "Semitic                    3\n",
       "Common Turkic              2\n",
       "Graeco-Phrygian            2\n",
       "South Dravidian            2\n",
       "Armenic                    2\n",
       "Finnic                     2\n",
       "Sinitic                    2\n",
       "Egyptian                   1\n",
       "Korean                     1\n",
       "North-Central Atlantic     1\n",
       "Japanesic                  1\n",
       "Swedish Sign               1\n",
       "Basque                     1\n",
       "Hungarian                  1\n",
       "Vietic                     1\n",
       "Malayo-Polynesian          1\n",
       "Name: genus, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genus['genus'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-marks",
   "metadata": {},
   "source": [
    "Genus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "living-disorder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######\n",
      "Mean and standard deviation over the different samples:\n",
      "r(Probe-L,las) -0.38182535755097863 SD: 0.11888433556930283\n",
      "r(Probe-A,las) -0.5273456827921336 SD: 0.09996750663056896\n",
      "r(bpe,las) -0.26195625642009585 SD: 0.09251593661171925\n",
      "r(msl,las) -0.13904044925133746 SD: 0.12073535811566322\n",
      "r(mwl,las) -0.3588640049679678 SD: 0.10401714822700062\n",
      "r(l2v,las) -0.38986011293399087 SD: 0.06740711116237684\n"
     ]
    }
   ],
   "source": [
    "deprel_means= [] \n",
    "struct_means= []\n",
    "bpe_means= []\n",
    "msl_means= []\n",
    "mwl_means= []\n",
    "l2v_means= []\n",
    "for s in range(1, 91): #random seeds\n",
    "    tree_sample_columns=sample_treebanks(las, s, \"columns\")  #returns a list with the a random sample of treebanks. The new sample will have only one treebank per language\n",
    "    tree_sample_rows=sample_treebanks(las, s, \"rows\")  #returns a list with the a random sample of treebanks. The new sample will have only one treebank per language\n",
    "    prefixes=sample_phylogenetic('genus', genus, 1,s)\n",
    "    randomsample_columns=[]\n",
    "    for t in tree_sample_columns:\n",
    "        for p in prefixes: #prefixes\n",
    "            if p in t:\n",
    "                #print(t,p)\n",
    "                randomsample_columns.append(t)\n",
    "                next\n",
    "                \n",
    "    randomsample_rows=[]\n",
    "    for t in tree_sample_rows:\n",
    "        for p in prefixes: #prefixes\n",
    "            if p in t:\n",
    "                #print(t,p)\n",
    "                randomsample_rows.append(t)\n",
    "                next\n",
    "    #if len(randomsample) != len(strings):\n",
    "        #print(len(finalsample), len(strings),\"ERROR\")\n",
    "    \n",
    "    #We addapt the dataframes (rows and columns) so they contain only the treebanks in the random sample \n",
    "\n",
    "    bpe_sampled=bpe[[c for c in bpe.columns if c in randomsample_columns]]\n",
    "    bpe_sampled=bpe_sampled.loc[bpe_sampled.index.intersection(randomsample_rows)] \n",
    "\n",
    "    l2v_sampled=l2v[[c for c in l2v.columns if c in randomsample_columns]]\n",
    "    l2v_sampled=l2v_sampled.loc[l2v_sampled.index.intersection(randomsample_rows)]  \n",
    "\n",
    "    las_sampled=las[[c for c in las.columns if c in randomsample_columns]]\n",
    "    las_sampled=las_sampled.loc[las_sampled.index.intersection(randomsample_rows)]  \n",
    "\n",
    "    msl_sampled=msl[[c for c in msl.columns if c in randomsample_columns]]\n",
    "    msl_sampled=msl_sampled.loc[msl_sampled.index.intersection(randomsample_rows)]  \n",
    "\n",
    "    mwl_sampled=mwl[[c for c in mwl.columns if c in randomsample_columns]]\n",
    "    mwl_sampled=mwl_sampled.loc[mwl_sampled.index.intersection(randomsample_rows)]  \n",
    "\n",
    "    struct_sampled=struct[[c for c in struct.columns if c in randomsample_columns]]\n",
    "    struct_sampled=struct_sampled.loc[struct_sampled.index.intersection(randomsample_rows)]  \n",
    "\n",
    "    deprel_sampled=deprel[[c for c in deprel.columns if c in randomsample_columns]]\n",
    "    deprel_sampled=deprel_sampled.loc[deprel_sampled.index.intersection(randomsample_rows)]\n",
    "    \n",
    "    \n",
    "    deprel_means.append( correlation_flatten(deprel_sampled, las_sampled)) \n",
    "    struct_means.append(correlation_flatten(struct_sampled, las_sampled))\n",
    "    bpe_means.append(correlation_flatten(bpe_sampled, las_sampled))\n",
    "    msl_means.append(correlation_flatten(msl_sampled, las_sampled))\n",
    "    mwl_means.append(correlation_flatten(mwl_sampled, las_sampled))\n",
    "    l2v_means.append(correlation_flatten(l2v_sampled, las_sampled))\n",
    "    \n",
    "#We print the mean taking into account all the random samples of treebanks:\n",
    "print(\"######\")\n",
    "print (\"Mean and standard deviation over the different samples:\")\n",
    "print (\"r(Probe-L,las)\", statistics.mean(deprel_means), \"SD:\", statistics.stdev(deprel_means))\n",
    "print(\"r(Probe-A,las)\",statistics.mean(struct_means), \"SD:\", statistics.stdev(struct_means) )\n",
    "print(\"r(bpe,las)\", statistics.mean(bpe_means), \"SD:\", statistics.stdev(bpe_means) )\n",
    "print(\"r(msl,las)\", statistics.mean(msl_means), \"SD:\", statistics.stdev(msl_means) )\n",
    "print(\"r(mwl,las)\", statistics.mean(mwl_means), \"SD:\", statistics.stdev(mwl_means) )\n",
    "print(\"r(l2v,las)\", statistics.mean(l2v_means), \"SD:\", statistics.stdev(l2v_means) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-denmark",
   "metadata": {},
   "source": [
    " - **Family level**\n",
    " \n",
    "Calculating correlations for the treebanks random samples (one treebank per linguistic family):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "greater-freedom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######\n",
      "Mean and standard deviation over the different samples:\n",
      "r(Probe-L,las) -0.3234887293325139 SD: 0.12697717037461523\n",
      "r(Probe-A,las) -0.5023880172839862 SD: 0.09328706249790328\n",
      "r(bpe,las) -0.10309658502713762 SD: 0.09195194518140425\n",
      "r(msl,las) -0.1641456815316146 SD: 0.1659228652546703\n",
      "r(mwl,las) -0.3366129749372456 SD: 0.11314834784055636\n",
      "r(l2v,las) -0.34817651671308103 SD: 0.05537272537558211\n"
     ]
    }
   ],
   "source": [
    "deprel_means= [] \n",
    "struct_means= []\n",
    "bpe_means= []\n",
    "msl_means= []\n",
    "mwl_means= []\n",
    "l2v_means= []\n",
    "for s in range(1, 91): #random seeds\n",
    "    tree_sample_columns=sample_treebanks(las, s, \"columns\")  #returns a list with the a random sample of treebanks. The new sample will have only one treebank per language\n",
    "    tree_sample_rows=sample_treebanks(las, s, \"rows\")  #returns a list with the a random sample of treebanks. The new sample will have only one treebank per language\n",
    "    prefixes=sample_phylogenetic('family', genus, 1,s)\n",
    "    randomsample_columns=[]\n",
    "    for t in tree_sample_columns:\n",
    "        for p in prefixes: #prefixes\n",
    "            if p in t:\n",
    "                #print(t,p)\n",
    "                randomsample_columns.append(t)\n",
    "                next\n",
    "                \n",
    "    randomsample_rows=[]\n",
    "    for t in tree_sample_rows:\n",
    "        for p in prefixes: #prefixes\n",
    "            if p in t:\n",
    "                #print(t,p)\n",
    "                randomsample_rows.append(t)\n",
    "                next\n",
    "    #if len(randomsample) != len(strings):\n",
    "        #print(len(finalsample), len(strings),\"ERROR\")\n",
    "    \n",
    "    #We addapt the dataframes (rows and columns) so they contain only the treebanks in the random sample \n",
    "\n",
    "    bpe_sampled=bpe[[c for c in bpe.columns if c in randomsample_columns]]\n",
    "    bpe_sampled=bpe_sampled.loc[bpe_sampled.index.intersection(randomsample_rows)] \n",
    "\n",
    "    l2v_sampled=l2v[[c for c in l2v.columns if c in randomsample_columns]]\n",
    "    l2v_sampled=l2v_sampled.loc[l2v_sampled.index.intersection(randomsample_rows)]  \n",
    "\n",
    "    las_sampled=las[[c for c in las.columns if c in randomsample_columns]]\n",
    "    las_sampled=las_sampled.loc[las_sampled.index.intersection(randomsample_rows)]  \n",
    "\n",
    "    msl_sampled=msl[[c for c in msl.columns if c in randomsample_columns]]\n",
    "    msl_sampled=msl_sampled.loc[msl_sampled.index.intersection(randomsample_rows)]  \n",
    "\n",
    "    mwl_sampled=mwl[[c for c in mwl.columns if c in randomsample_columns]]\n",
    "    mwl_sampled=mwl_sampled.loc[mwl_sampled.index.intersection(randomsample_rows)]  \n",
    "\n",
    "    struct_sampled=struct[[c for c in struct.columns if c in randomsample_columns]]\n",
    "    struct_sampled=struct_sampled.loc[struct_sampled.index.intersection(randomsample_rows)]  \n",
    "\n",
    "    deprel_sampled=deprel[[c for c in deprel.columns if c in randomsample_columns]]\n",
    "    deprel_sampled=deprel_sampled.loc[deprel_sampled.index.intersection(randomsample_rows)]\n",
    "    \n",
    "    deprel_means.append( correlation_flatten(deprel_sampled, las_sampled)) \n",
    "    struct_means.append(correlation_flatten(struct_sampled, las_sampled))\n",
    "    bpe_means.append(correlation_flatten(bpe_sampled, las_sampled))\n",
    "    msl_means.append(correlation_flatten(msl_sampled, las_sampled))\n",
    "    mwl_means.append(correlation_flatten(mwl_sampled, las_sampled))\n",
    "    l2v_means.append(correlation_flatten(l2v_sampled, las_sampled))\n",
    "    \n",
    "#We print the mean taking into account all the random samples of treebanks:\n",
    "print(\"######\")\n",
    "print (\"Mean and standard deviation over the different samples:\")\n",
    "print (\"r(Probe-L,las)\", statistics.mean(deprel_means), \"SD:\", statistics.stdev(deprel_means))\n",
    "print(\"r(Probe-A,las)\",statistics.mean(struct_means), \"SD:\", statistics.stdev(struct_means) )\n",
    "print(\"r(bpe,las)\", statistics.mean(bpe_means), \"SD:\", statistics.stdev(bpe_means) )\n",
    "print(\"r(msl,las)\", statistics.mean(msl_means), \"SD:\", statistics.stdev(msl_means) )\n",
    "print(\"r(mwl,las)\", statistics.mean(mwl_means), \"SD:\", statistics.stdev(mwl_means) )\n",
    "print(\"r(l2v,las)\", statistics.mean(l2v_means), \"SD:\", statistics.stdev(l2v_means) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
